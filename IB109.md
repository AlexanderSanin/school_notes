# IB109 Návrh a implementace paralelních systémů

* písemný test (> 60 %)

> _"Běda vám, jestli přijdete příště!"_

>_"Tam se prostě svlíknete a všichni ostatní na vás vidí. Což ještě není tak hrozný, když na vás vidí, ale oni na vás můžou šahat."_

> _"Podle `make` potom v Brně začali říkat 'maké'."_

### Důvody vývoje paralelních systémů
* **výkon** -- procesory mají fyzické hranice (nemohou se zrychlovat donekonečna), při zvýšení počtu paměťových modulů roste propustnost
* **provedlitelnost** -- potřebujeme to včas a máme toho hodně, tak to musíme udělat paralelně
* **bezpečnost** -- duplikujeme části systému pro případ napadení, havárie nebo ztráty
* **cena** -- levnější údržba při oddělení jednotlivých procesů

### Paralelní výpočty
**multitasking** -- plánovací jednotka je proces

* na jednom jádru -- aplikace se střídají
* na více jádrech -- každá aplikace má své jádro

**multithreading** -- plánovací jednotka je vlákno, vlákna jedné aplikace mohou běžet na více jádrech

#### Flynnova klasifikace
* **Single Instruction Single Data**
* **Single Instruction Multiple Data**
* **Multiple Instruction Multiple Data**
* **Multiple Instruction Single Data**

#### Distribuovaný systém
* systém, který je specifikován po částech
* jednotlivé procesy či vlákna jsou autonomní
* **emergentní jev** -- chování systému jako celku (mravenci s cukrem)
* systém se synchronizuje a komunikuje
* problémy distribuovaného systému: nedeterministické chování, deadlock, livelock, stárnutí, přetečení bufferů (hromadění dat), ztráta výkonu (aktivní čekání)

#### Náročnost vývoje paralelních systémů
* specifikace souběžných úkolů
* paralelní algoritmy
* nedostačující vývojová prostředí
* nedeterminismus při simulaci
* rychlý vývoj, zastarání použitých technologií

**HPC** (High Performance Computing) -- výpočty na vysoce paralelních platformách

## Programování v prostředí se sdílenou pamětí
* více procesorů, více jádrové procesory nebo procesory, které umí SMT, přistupují k jedné paměti více procesy/vlákny
* hrozí přeuspořádání instrukcí nebo odložení zápsů do paměti

### SMT (Simultální MultiThreading)
* duplikace registrů (nebo jiných částí procesoru)
* procesor pracuje na dvou věcech naráz (když je v první prodleva kvůli paměti, počítá druhou)
* př. Inter Pentium 4 (Hyper-Threading Technology)

### Proces vs. vlákno
#### Proces
* = jednotka výpočtu, ideálně je izolovaný
* vytvoření procesu je dražší
* ID procesu a vlastníka, proměnné prostředí, pracovní adresář, kód, registry, zásobník, halda, orevřené soubory a sdílené knihovny, reakce na signály, kanály IPC

#### Vlákno
* = potomek procesu, není izolováno
* vytvoření vlákna je levnější
* v rámci procesu nemá soukromí, sdílejí globální proměnné
* má vlastní zásobník, registry a frontu signálů

### Efektivní využití cache
* menší a rychlejší paměť
* koherence -- existuje právě jedna platná hodnota asociovaná s daným paměťovým místem

**cache line** -- blok paměti natažený z operační paměti do cache

**hit radio** -- úspěšnost obsloužení požadavků daty z cache

**vylití cache** -- zahození části obsahu kvůli uvolnění místa

**výprask** -- mám virtuální stránky na disku a pak dlouho trvá, když se stránky přesouvají

**memalign** -- zarovnaná alokace paměti

**false sharing** -- problém  snižující výkonnost, když data sdílí cache paměť a procesoru, který s daty pracuje je cache s daty vylita

**nestálé proměnné** -- každý mezivýpočet nemusí být uložen do paměti, ale může zůstat v registru, kde na něj ostatní vlákna nevidí, klíčové slovo `volatile`

**paměťová bariéra** -- slouží k synchronizaci, instrukce `mfence`

### Rizika
**reace condition** -- výsledek programu záleží na proložení instrukcí jednotlivých vláken, projevuje se nedeterministickým výstupem, operace pak nemusí být atomická

**relativní rychlost výpočtu** -- rychlost výpočtu jednotlivých vláken je relativní

**deadlock** -- inkremetální požadavky, zámky jsou unikátní a sdílené, zámky jsou alokovány v daném pořadí

**livelock** -- vlákno není schopno pokročit dál, protože mu v tom brání ostatní vlákna (není naplněna podmínka apod.)

**thread-safe** -- bezpečné vlákno, které lze provést souběžně s dalšími

**re-entrantní procedura** -- obsluha přerušení, kdy přijde další přerušení

**serializace globálních proměnných** -- seřazení do řady požadavků na změny

**kritická sekce** -- část kódu, kde přistupujeme ke globálním proměnným, nesmí být proložena instrukcemi jiného vlákna

* není-li zdroj aktuálně dostupný, mohou nastat tyto varianty:
    * **spinlock** -- (aktivní čekání) _"Už tam budem?"_
    * **uspání** -- zkusí to za nějakou dobu nebo je probudí jiné vlákno
* pokud je zdroj odemčen, přístup získá náhodné čekající vlákno
* rizika zamykání: uváznutí, stárnutí, snížení výkonnosti
* Petersonův algoritmus -- spravedlivý algoritmus, který nezpůsobuje strárnutí ani uváznutí

#### Nebezpečné postupy
* nekontrolovaný přístup ke globálním proměnným na haldě
* alokace a dealokace např. souborů
* přístup skrz ukazatele

## POSIX Threads
* standardní rozhraní pro vlákna
* `#include <pthread.h>`
* proces má 1 hlavní vlákno, které rekurzivně vytváří další vlákna

### Posix Thread API - funkcionalita
* správa vláken
  * **vytvoření nového vlákna** - funkce `pthread_create`, při úspěchu vrací `0`
```
int pthread_create(*vytvorene_vlakno,
               *atributy,
               *fuknce_vlakna,
               *parametry_funkce_vlakna)
```
  * **ukončení vlákna** - `void pthread_exit(*navratova_hodnota)` (před ukončením musíme uvolnit prostředky) nebo `int pthread_cancel(*vlakno)`, když je rušeno jiným vláknem, vrací 0, když vlákno stále existuje, uvolní všechny prostředky
  * **spojování vláken** -- vlákna dělíme na spojitelné a nespojitelná, je dobré nastavit, jaká jsou, spojujeme funkcí `int pthread_join(vlakno, *navratova_hodnota)`
  * **nastavení, zjištění stavu**
* vzájemné vyloučení (mutex)
* podmínkové proměnné -- komunikace a synchronizace vláken

### Vzájemné vyloučení (Mutual Exlusion, Mutex)
* zámek
* typy -- nastavujeme funkcí pthread `mutexattr_settype_np`
  * **normální mutex**
  * **rekurzivní mutex** -- muže být zamknutý opakovaně, následně musí být stejněkrát odemknut
  * **normální mutex s kontrolou chyby** -- ohlásí chybu při pokusu o druhé zamčení

`int pthread_mutex_init(*mutex, *atributy)`

`int pthread_mutex_lock(*mutex)`

`int pthread_mutex_unlock(*mutex)`

`int pthread mutex trylock (*mutex)` - zkusí zamčít, pokud se to nepovede, nezařazuje proces do fronty čekajících, pouze vrátí `EBUSY`, využítí při aktiviním čekání

### Podmínkové proměnné v POSIX Threads
* aktivní čekání nebo uspání, k následnému probuzení při určité události se využívají podmínkové proměnné
* vyžaduje použití mutexu
* inicializace podmínkové proměnné: `int pthread_cond_init (*promenna, *atributy)`
* zničení podmínkové proměnné: `int pthread_cond_destroy(*promenna)`
* svážeme mutex s podmínkovou proměnnou, která po uvolnění mutexu vzudí buď jedno vlákno, nebo všechna čekající
* uspané vlákno se probudí buď signálem od podmínkové proměnné nebo po vypršení časového limitu 

### TSD (Thread Specific Data)
* globální proměnné s různými hodnotami pro různá vlákna
* implementace pomocí pole nebo jako slovník klíč:hodnota (POSIX - vlákno má klíč `pthread_key_create`)

### WRRM (Write-Rarely-Read-Many)
* chceme, aby čtení mohlo probíhat souběžně
* zapisovatel má přednost, i když čeká
* zapisuje se sériově, čte se paralelně
* zjištění kurzu v bance

### Nástroje sloužící k synchronizaci
**bariéra** -- synchronizační primitivum, podmíněné čekání, než doběhnou ostatní vlákna, implementace pomocí mutexů nebo podmínkové proměnné a počítadla

**semafor** -- lze použít pro synchronizaci procesů (nebo vláken), může být zapnut a vypnut různými vlákny v rámci jednoho procesu (u mutexů to nejde)

**monitor** -- označuje kritickou sekci

### Vlákna v MS Windows
* synchronizační prostředky fungují i mezi procesy
* jeden typ pro všechny entity `HANDLE`
* `CreateThread`, `ThreadExit`

## Lock-Free programování
* implementace paralelních aplikací bez použití mutexů nebo jiných makro-synchronizačních mechanizmů
* výhody: nemůže nastat uváznutí či stárnutí, rychlejší
* nevýhody: náročnější na implementaci
* většinou jedna velký atomická instrukce

**waitfree procedura** -- nedochází k čekání

**lockfree procedura** -- alespoň 1 vlákno dokončí činnost, nenastane deadlock

### CAS (Compare and Swap/Set)
* atomická instrukce procesoru
* pokud je na adrese očekávaná hodnota, nahradí se za ni nová, vrací Ttrue nebo False podle úspěchu

#### ABA problém
* mezi kontrolou a CAS může ještě někdo změnit očekávanou hodnotu tam a zpět
* řešení: přidáme čaosvý údaj

### WRRM Mapa
* příklad z kurzem měny
* implementujeme s použitím CAS
* při čtení se nic nezamyká
* při zápisu se vytvoří kopie, v té se změní potřebná data a následně se atomicky zamění (CAS) za data původní (pomocí ukazatele)
* lockfree, ale ne waitfree (když upravují dva naráz, musí čekat)
* dealokace mapy: držíme si počet vláken, které pracují s daným ukazatelem

#### Modifikace WRRM mapy
* Procedura Update -- provádí změny, pokud žádné jiné vlákno ukazatel nepoužívá
* Procedura Lookup -- zvýší čítač, přistoupí ke struktuře, ukončí práci, sníží čítač, podmíněně dealokuje

#### CAS2
* prevede CAS na 2 slova paměti (musí být vedle sebe)
* -> WRRMBNTM (Write Rarely Read Many, But Not To Many

### Lock-Free Garbage Collector
**hazardní ukazatel** -- nelze dealokovat, někdo jiný k němu přistupuje
* udžuji si seznam hazardních ukazatelů a dealokuji jen ty ukazatele, které v něm nejsou
* občas seznam projdu a dealokuji ty, které již nejsou hazardní
* seznam je globální, tedy musím ošetřit paralelní přístupy
* **metoda Acquire()** -- přidání ukazatele do seznamu
* **metoda Release()** -- zneplatnění objektu
* **metoda Retire()** -- odloží ukazatel do seznamu
* **metoda Scan()** -- hledá v setříděné kopii seznamu ukazatelů, jestli se daný ukazatel ještě někde používá, nepoužíváné dealokuje

### Další možnosti lockfree programování
* MCAS (Multiple CASS) -- libovolná velikost struktury
* Transakční paměť
* Load-Link/Store-Conditional -- jak CAS na jiných procesorech, instrukce LL a SC

## OpenMP, TBB, C++11
* POSIX Threads a Lock free přístup jsou na příliž nízké úrovni, chceme něco na úrovni programovacího jazyka

### OpenMP
* co má být provedeno paralelně nikoli jak
* značky pro překlad se píšou do kódu ("tuto funkci teď proveď paralelně) (!)
* překladač si určuje vhodný počet vláken a celý zbytek implementace
* zbytek kódu běží sekvenčně
* paralelní bloky lze i zanořovat
* direktivy:

#### `#pragma omp parallel`
* následujcí blok {} se provede paralelně
* podporuje i podmíněné spuštění 

##### Datová lokalita
* `private` -- z originálu se vytvoří lokální proměnné
* `firstprivate` -- `private` + inicializace na hodnotu originálu
* `shared` -- proměnná se sdílí a přístup k ní je serializován
* `default shared/none` -- vše sdíleno / uvedeno jako shared nebo private
* `reduction` -- kombinace uvedených proměnných s pomocí daného operátoru

#### `#pragma omp for`
* iterace cyklu budou provedeny paralelně
* `private`, `firstprivate`, `reduction`
* `lastprivate` -- výsledek se uloží do proměnné, která bude dostupná i po skončení cyklu
* `ordered` -- kód proběhne ve stejné pořadí, jako by běžel sekvenčně
* `nowait` -- nemusí čekat, až doběhnou ostatní vlákna, nemusí se synchronizovat
* `schedule`
  * `static` -- rovnoměrné rozdělení
  * `dynamic` -- když množství práce jednotlivých instancí není konstantní a některé z vláken by mohlo skončit dřív
  * `guided` -- blok iterací = (nezpracovaných iterací / počet vláken)
  * `runtime` -- určení plánování až za běhu

#### `#pragma omp sections`
* v bloku `sections` vyznačíme jednotlivé bloky `section`, ty pak mohou být provedeny paralelně

#### `#pragma omp barrier`
* místo, kam musí dojít všechna vlákna
* musí být v části kódu, která se vždy provede, aby nebyla náhodou při překladu odstraněna

#### `#pragma omp single`
* následujcí sekce je prováděna právě jedním vláknem (je jedno kterým)

#### `#pragma omp master`
* stejné jako `single`, ale sekci provádí hlavní vlákno)

#### `#pragma omp critical`
* označení kritické sekce

#### `#pragma omp atomic`
#### `#pragma omp flush`
* zkopírování registr -> paměť -> registr

#### `#pragma omp threadprivate`
* přetrvávající globální proměnné
* přežijí i zánik vlákna

#### `#pragma omp copyin`
* stejné jako treadprivate, pouze s inicializací na původní hodnotu


* `void omp set num threads (int num threads)` -- nastavení počtu vláken
* `int omp get num threads ()` -- zjištění počtu vláken
* funkce pro: maximální počet vláken, identifikační kód vlákna, počet procesů, identifikace paralelního bloku



## Principy návrhu paralelních algoritmů

## Předávání zpráv v distribuované paměti, MPI

## Kolektivní komunikace

## Složitostní analýza paralelních programů
